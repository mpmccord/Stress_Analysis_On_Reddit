---
title: "Stress_Analysis_On_Reddit"
author: "Melanie McCord"
date: "9/30/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# load required packages
library(tidytext)
library(tidyverse)
library(caret)
library(stringr)
source("./model_training_functions/train_test_split.R")
source("./feature_creation_functions/create_bag_of_words_model.R")
source("./feature_creation_functions/create_sentiment_model.R")
source("./data_visualization_functions/plot_frequency_distribution.R")
source("./feature_selection_functions/remove_overly_correlated_features.R")

```
Now let's start off by reading in the training and test data.
```{r}
test_data <- read_csv("reddit_stress_data/dreaddit-test.csv", show_col_types = FALSE)
train_data <- read_csv("reddit_stress_data/dreaddit-train.csv", show_col_types = FALSE)
reddit_stress_data <- add_row(train_data, test_data)
```
First, I'll start by creating a bag of words representation on my data, marking unknown variables correspondingly.
```{r}
bag_of_words_with_unknowns <- CreateBagOfWordsWithUnknowns(reddit_stress_data)
```

Since we have our bag of words model, let's mutate to represent the proportion of words for that variable.
```{r}
stress_data_with_bow <- reddit_stress_data %>%
  select(-text) %>%
  left_join(bag_of_words_with_unknowns, by = "id")
head(stress_data_with_bow, 2)
```
Now removing the correlated features:
```{r}
label <- reddit_stress_data$label
text_features <- bag_of_words_with_unknowns
small_bag_of_words <- RemoveHighlyCorrelatedFeatures(text_features, "id", 0.5)
```
Now let's display the features
```{r}
head(small_bag_of_words, 2)
```
The correlation matrix is calculated like this: $\frac{\sum{(X_i - \bar{x})(y_i - \bar{y})}}{\sqrt{(X_i = \bar{x})^2(Y_i - \bar{y})}}$
