---
title: "Visualizing the Distribution of Words"
author: "Melanie McCord"
date: "10/14/2021"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidytext)
library(plotly)
library(tidyverse)
source("feature_creation_functions/create_bag_of_words_model.R")
```
# Part 1: Reading in the Data
First, we need to read in the data and join the training and test data.
```{r results='hide', echo=TRUE}
train_data <- read_csv("reddit_stress_data/dreaddit-train.csv", show_col_types = FALSE)
test_data <- read_csv("reddit_stress_data/dreaddit-test.csv", show_col_types = FALSE)
reddit_stress_data <- add_row(train_data, test_data)
```
Now we need to find the word distributions. We'll start by unnesting the tokens and training this on the full dataset.
```{r echo=TRUE}
words_tokenized <- reddit_stress_data %>%
  select(c("id", "text", "label", "subreddit")) %>%
  unnest_tokens(word, text) %>%
  mutate(word = gsub('[[:punct:]]+','', word)) %>%
  mutate(word = gsub('\\<[[:digit:]]+\\>', '%d%', word)) %>%
  anti_join(stop_words)
head(words_tokenized)
```
# Part 2: Understanding the General Structure of the Data
## Getting the Labels Distribution
```{r echo=TRUE}
label_counts <- reddit_stress_data %>%
  group_by(label) %>%
  count()
plot_ly(label_counts, x = ~label, y = ~n, type = "bar")
```
### Table of Subreddits
```{r}
label_counts
```


## Subreddit Distribution
```{r}
subreddit_counts <- reddit_stress_data %>%
  group_by(subreddit) %>%
  count()
subreddit_counts
plot_ly(subreddit_counts, x = ~subreddit, y = ~n, type = "bar")
```

## Labels By Subreddit
```{r}
# Stacked
reddit_stress_data %>%
  ggplot(aes(y=subreddit)) + geom_bar(aes(fill = as.factor(label)), position="stack")
```

# Part 3: Visualizing Top 20 Most Common Words Among the Data
Now let's see the most common words among the data (overall).
```{r}
GetTopNMostCommonWords <- function(df, num) {
  top_word_counts <- df %>%
    count(word) %>%
    arrange(desc(n))
  return (head(top_word_counts, num))
}
```

```{r}
num <- 15
top_10_full_data <- GetTopNMostCommonWords(words_tokenized, num)
```

Now I will plot the rop 20 most common words in the dataset
```{r}
ggplot(top_10_full_data, aes(x = reorder(word, desc(n)), y = n)) + geom_col(fill = "steelblue") + labs(title = "Top 10 Words from the Full Dataset", x = "Word", y = "Frequency")
```
Now let's see how this varies among label: stressed or non-stressed.
```{r}
stressed_data <- filter(words_tokenized, label == 0)
non_stressed_data <- filter(words_tokenized, label == 1)
```

Now let's plot them
```{r}
ggplot(GetTopNMostCommonWords(non_stressed_data, num), aes(x = reorder(word, desc(n)), y = n)) + geom_col(fill = "steelblue") + labs(title = "Top 10 Words from the Non-Stressed Dataset", x = "Word", y = "Frequency")
```
Now let's see the difference among stressed data.
```{r}
ggplot(GetTopNMostCommonWords(stressed_data, num), aes(x = reorder(word, desc(n)), y = n)) + geom_col(fill = "steelblue") + labs(title = "Top 10 Words from the Stressed Dataset", x = "Word", y = "Frequency")

```
# Visualizing the Distribution of Words By Label
```{r}
words_tokenized_by_subreddit_counts <- reddit_stress_data %>%
  select(c("id", "text", "label", "subreddit")) %>%
  unnest_tokens(word, text) %>%
  mutate(word = gsub('[[:punct:]]+','', word)) %>%
  mutate(word = gsub('\\<[[:digit:]]+\\>', '%d%', word)) %>%
  anti_join(stop_words) %>%
  group_by(subreddit) %>%
  count(word) %>%
  arrange(subreddit, desc(n))
head(words_tokenized_by_subreddit_counts)
```

# Visualizing the Distribution of Words By Subreddit
```{r}
words_tokenized_by_subreddit_counts <- reddit_stress_data %>%
  select(c("id", "text", "label", "subreddit")) %>%
  unnest_tokens(word, text) %>%
  mutate(word = gsub('[[:punct:]]+','', word)) %>%
  mutate(word = gsub('\\<[[:digit:]]+\\>', '%d%', word)) %>%
  anti_join(stop_words) %>%
  group_by(label) %>%
  count(word) %>%
  arrange(label, desc(n))
head(words_tokenized_by_subreddit_counts)
words_tokenized_by_subreddit_counts %>%
  top_n(10, n) %>%
  ungroup() %>%  
  mutate(label = as.factor(label)) %>%
  arrange(label, n) %>%  
  mutate(topic_r = row_number()) %>%
  ggplot(aes(word, n, fill = label)) + 
  geom_col() +
  facet_wrap(~ label, scales = "free") + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
```
Now let's plot them
```{r}
words_tokenized_by_subreddit_counts <- reddit_stress_data %>%
  select(c("id", "text", "label", "subreddit")) %>%
  unnest_tokens(word, text) %>%
  mutate(word = gsub('[[:punct:]]+','', word)) %>%
  mutate(word = gsub('\\<[[:digit:]]+\\>', '%d%', word)) %>%
  anti_join(stop_words) %>%
  group_by(subreddit) %>%
  count(word) %>%
  arrange(subreddit, desc(n))
head(words_tokenized_by_subreddit_counts)
words_tokenized_by_subreddit_counts %>%
  top_n(10, n) %>%
  ungroup() %>%  
  arrange(subreddit, n) %>%  
  mutate(topic_r = row_number()) %>%
  ggplot(aes(word, n, fill = subreddit)) + 
  geom_col() +
  facet_wrap(~ subreddit, scales = "free") + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
```
Now looking at a subset.
```{r}
words_tokenized_by_subreddit_counts <- reddit_stress_data %>%
  select(c("id", "text", "label", "subreddit")) %>%
  filter(subreddit == "almosthomeless" | subreddit == "anxiety" | subreddit == "survivorsofabuse") %>%
  unnest_tokens(word, text) %>%
  mutate(word = gsub('[[:punct:]]+','', word)) %>%
  mutate(word = gsub('\\<[[:digit:]]+\\>', '%d%', word)) %>%
  anti_join(stop_words) %>%
  group_by(subreddit) %>%
  count(word) %>%
  arrange(subreddit, desc(n))
head(words_tokenized_by_subreddit_counts)
words_tokenized_by_subreddit_counts %>%
  top_n(10, n) %>%
  ungroup() %>%  
  arrange(subreddit, n) %>%  
  mutate(topic_r = row_number()) %>%
  ggplot(aes(word, n, fill = subreddit)) + 
  geom_col() +
  facet_wrap(~ subreddit, scales = "free") + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
```


# Part 4: Visualizing the Distribution of Sentiment
## Overall
```{r}
ggplot(reddit_stress_data, aes(x = sentiment)) + geom_boxplot(fill = "steelblue", bins = 50) + labs(title = "Distribution of Sentiment")
mx <- 0
ggplot(reddit_stress_data, aes(x = sentiment)) + geom_histogram(fill = "steelblue", bins = 50) + labs(title = "Distribution of Sentiment") + geom_vline(xintercept = mx, col = "red", lwd = 1) + annotate("text", x = 0.1, y = 400, label = "Neutral")
```
## By Label
```{r}
ggplot(reddit_stress_data, aes(x = sentiment)) + geom_boxplot(fill = "steelblue") + labs(title = "Distribution of Sentiment") + facet_wrap(~ label)

ggplot(reddit_stress_data, aes(x = sentiment)) + geom_histogram(fill = "steelblue", bins = 50) + labs(title = "Distribution of Sentiment") + facet_wrap(~ label) + geom_vline(xintercept = mx, col = "red", lwd = 1) + annotate("text", x = 0.2, y = 400, label = "Neutral")
```
## By Subreddit
```{r}
ggplot(reddit_stress_data, aes(x = sentiment)) + geom_boxplot(fill = "steelblue") + labs(title = "Distribution of Sentiment") + facet_wrap(~ subreddit)
```
```{r}
reddit_stress_data %>%
  filter(subreddit == "ptsd" | subreddit == "stress") %>%
  ggplot(aes(x = sentiment)) + geom_boxplot(fill = "steelblue") + labs(title = "Distribution of Sentiment") + facet_wrap(~ subreddit)
```

## By Label and Subreddit
```{r}
ggplot(reddit_stress_data, aes(x = sentiment)) + geom_boxplot(fill = "steelblue") + labs(title = "Distribution of Sentiment") + facet_grid(subreddit ~ label, switch ="y") + theme(strip.text.y.left = element_text(angle = 0))

```
Now looking at a selection of these:
```{r}
reddit_stress_data %>%
  filter(subreddit == "assistance" | subreddit == "stress") %>%
  ggplot(aes(x = sentiment)) + geom_boxplot(fill = "steelblue") + labs(title = "Distribution of Sentiment") + facet_grid(subreddit ~ label, switch ="y") + theme(strip.text.y.left = element_text(angle = 0))
```

